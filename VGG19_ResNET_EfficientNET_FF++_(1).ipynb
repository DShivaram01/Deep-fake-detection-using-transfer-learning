{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DShivaram01/DataScienceEcosystem.ipynb/blob/main/VGG19_ResNET_EfficientNET_FF%2B%2B_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UhjbVgXIGq6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# Load the pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the function to extract frames from the video\n",
        "def extract_frames(video_path, num_frames=10):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % (cap.get(cv2.CAP_PROP_FRAME_COUNT) // num_frames) == 0:\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = frame / 255.0\n",
        "            frame = np.expand_dims(frame, axis=0)\n",
        "            frames.append(frame)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    frames = np.concatenate(frames, axis=0)\n",
        "    return frames\n",
        "\n",
        "real_videos_dir = ['/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/800.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/801.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/802.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/803.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/804.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/805.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/806.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/807.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/808.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/809.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/810.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/811.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/812.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/813.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/814.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/815.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/816.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/817.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/818.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/819.mp4','/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/820.mp4']\n",
        "real_labels = np.zeros(6)\n",
        "\n",
        "real_frames = []\n",
        "for video_path in real_videos_dir:\n",
        "    frames = extract_frames(video_path)\n",
        "    real_frames.append(frames)\n",
        "real_frames = np.concatenate(real_frames, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "fake_videos_dir = ['/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/000_003.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/001_870.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/002_006.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/003_000.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/004_982.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/005_010.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/006_002.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/007_132.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/008_990.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/009_027.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/010_005.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/011_805.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/012_026.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/013_883.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/014_790.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/015_919.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/016_209.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/017_803.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/018_019.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/019_018.mp4','/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/020_344.mp4']\n",
        "fake_labels = np.ones(6)\n",
        "\n",
        "fake_frames = []\n",
        "for video_path in fake_videos_dir:\n",
        "    frames = extract_frames(video_path)\n",
        "    fake_frames.append(frames)\n",
        "fake_frames = np.concatenate(fake_frames, axis=0)\n",
        "\n",
        "# Combine the real and fake frames and labels\n",
        "# Combine the real and fake frames and labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YffSID9LotCp",
        "outputId": "45c7e9e7-99de-412b-d537-0a346599eea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgaqQ6YyTs9q",
        "outputId": "295da82a-e4e4-469a-8445-d7f39f18f4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_frames shape: (456, 224, 224, 3)\n",
            "all_labels shape: (456,)\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 372s 32s/step - loss: 1.9315e-11 - accuracy: 1.0000 - val_loss: 5.3989e-11 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 370s 31s/step - loss: 1.9307e-11 - accuracy: 1.0000 - val_loss: 5.3977e-11 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 357s 30s/step - loss: 1.9304e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 355s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 357s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 355s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 357s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 355s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 357s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 357s 30s/step - loss: 1.9303e-11 - accuracy: 1.0000 - val_loss: 5.3973e-11 - val_accuracy: 1.0000\n",
            "15/15 [==============================] - 345s 23s/step - loss: 2.6298e-11 - accuracy: 1.0000\n",
            "Validation loss: 2.6297613392456398e-11\n",
            "Validation accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "all_frames = np.concatenate((real_frames, fake_frames), axis=0)\n",
        "all_labels = np.concatenate((real_labels, fake_labels), axis=0)\n",
        "all_labels = np.repeat(all_labels, all_frames.shape[0])\n",
        "\n",
        "num_samples = len(all_frames)\n",
        "all_frames = all_frames[:num_samples]\n",
        "all_labels = all_labels[:num_samples]\n",
        "# Verify the shapes of all_frames and all_labels\n",
        "print('all_frames shape:', all_frames.shape)\n",
        "print('all_labels shape:', all_labels.shape)\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    all_frames,\n",
        "    all_labels,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "score = model.evaluate(all_frames, all_labels)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvfv6NMZA3f2"
      },
      "outputs": [],
      "source": [
        "# def preprocess_video(video_path):\n",
        "#     frames = extract_frames(video_path)  # Use the extract_frames function defined earlier\n",
        "#     frames = np.array(frames)\n",
        "#     frames = np.resize(frames, (frames.shape[0], 224, 224, 3))\n",
        "#     frames = frames / 255.0\n",
        "#     return frames\n",
        "\n",
        "# # Define the input video path\n",
        "# input_video_path = \"/content/drive/MyDrive/FF++/manipulated_sequences/Deepfakes/c23/videos/000_003.mp4\"\n",
        "\n",
        "# # Preprocess the input video\n",
        "# input_frames = preprocess_video(input_video_path)\n",
        "\n",
        "# # Make predictions using the model\n",
        "# predictions = model.predict(input_frames)\n",
        "\n",
        "# # Interpret the predictions\n",
        "# mean_prediction = np.mean(predictions)\n",
        "# if mean_prediction >= 0.5:\n",
        "#     print(\"The input video is classified as fake.\")\n",
        "# else:\n",
        "#     print(\"The input video is classified as real.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQLRZuEvkmJt"
      },
      "outputs": [],
      "source": [
        "!pip install efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUrzvE6BkmVI"
      },
      "outputs": [],
      "source": [
        "from efficientnet.keras import EfficientNetB6\n",
        "\n",
        "base_model = EfficientNetB6(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model_e = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model_e.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_e.fit(\n",
        "    all_frames,\n",
        "    all_labels,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "score = model_e.evaluate(all_frames, all_labels)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC_XkyBwlWWT"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model_r = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "model_r.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_r.fit(\n",
        "    all_frames,\n",
        "    all_labels,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the validation data\n",
        "score = model_r.evaluate(all_frames, all_labels)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttQ_uQaUwkvt"
      },
      "outputs": [],
      "source": [
        "vgg_predictions = model.predict(input_frames)\n",
        "resnet_predictions = model_r.predict(input_frames)\n",
        "effnet_predictions = model_e.predict(input_frames)\n",
        "\n",
        "# Count the number of predictions for each class (0: real, 1: fake)\n",
        "class_counts = np.bincount([np.argmax(vgg_predictions), np.argmax(resnet_predictions), np.argmax(effnet_predictions)])\n",
        "\n",
        "# Get the index of the class with the highest count\n",
        "final_prediction = np.argmax(class_counts)\n",
        "\n",
        "# Print the final prediction\n",
        "if final_prediction == 0:\n",
        "    print(\"The input video is predicted to be real.\")\n",
        "else:\n",
        "    print(\"The input video is predicted to be fake.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbXivddUx4N4"
      },
      "outputs": [],
      "source": [
        "from keras.models import save_model\n",
        "\n",
        "# Save the VGG19 model\n",
        "model.save(\"vgg_model.h5\")\n",
        "\n",
        "# Save the ResNet50 model\n",
        "model_r.save(\"resnet_model.h5\")\n",
        "\n",
        "# Save the EfficientNet model\n",
        "model_e.save(\"effnet_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0esKe9YGiay-"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the VGG19 model\n",
        "vgg_model = load_model(\"vgg_model.h5\")\n",
        "\n",
        "# Load the ResNet50 model\n",
        "resnet_model = load_model(\"resnet_model.h5\")\n",
        "\n",
        "# Load the EfficientNet model\n",
        "effnet_model = load_model(\"effnet_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCTlALUtmleK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications import VGG19, ResNet50\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Load the pre-trained VGG19 model\n",
        "# vgg_base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# # Freeze the layers in the VGG19 base model\n",
        "# for layer in vgg_base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Add a new output layer on top of the VGG19 base model\n",
        "# vgg_x = vgg_base_model.output\n",
        "# vgg_x = Flatten()(vgg_x)\n",
        "# vgg_predictions = Dense(1, activation='sigmoid')(vgg_x)\n",
        "# vgg_model = Model(inputs=vgg_base_model.input, outputs=vgg_predictions)\n",
        "\n",
        "# # Load the pre-trained ResNet model\n",
        "# resnet_base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# # Freeze the layers in the ResNet base model\n",
        "# for layer in resnet_base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Add a new output layer on top of the ResNet base model\n",
        "# resnet_x = resnet_base_model.output\n",
        "# resnet_x = Flatten()(resnet_x)\n",
        "# resnet_predictions = Dense(1, activation='sigmoid')(resnet_x)\n",
        "# resnet_model = Model(inputs=resnet_base_model.input, outputs=resnet_predictions)\n",
        "\n",
        "# # Load the pre-trained EfficientNet model\n",
        "# efficientnet_base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "# # Freeze the layers in the EfficientNet base model\n",
        "# for layer in efficientnet_base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Add a new output layer on top of the EfficientNet base model\n",
        "# effnet_x = efficientnet_base_model.output\n",
        "# effnet_x = Flatten()(effnet_x)\n",
        "# effnet_predictions = Dense(1, activation='sigmoid')(effnet_x)\n",
        "# effnet_model = Model(inputs=efficientnet_base_model.input, outputs=effnet_predictions)\n",
        "\n",
        "# # Combine the models into a voting classifier\n",
        "# voting_classifier = VotingClassifier(\n",
        "#     estimators=[\n",
        "#         ('vgg', vgg_model),\n",
        "#         ('resnet', resnet_model),\n",
        "#         ('effnet', effnet_model)\n",
        "#     ],\n",
        "#     voting='soft'  # Use soft voting to obtain probabilities\n",
        "# )\n",
        "\n",
        "# Define the function to extract frames from the video\n",
        "def extract_frames(video_path, num_frames=10):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % (cap.get(cv2.CAP_PROP_FRAME_COUNT) // num_frames) == 0:\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            frame = frame / 255.0\n",
        "            frame = np.expand_dims(frame, axis=0)\n",
        "            frames.append(frame)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    frames = np.concatenate(frames, axis=0)\n",
        "    return frames\n",
        "\n",
        "# Define the input video path\n",
        "input_video_path = \"/content/drive/MyDrive/FF++/original_sequences/youtube/c23/videos/003.mp4\"\n",
        "\n",
        "# Preprocess the input video frames\n",
        "input_frames = extract_frames(input_video_path)\n",
        "input_frames = np.array(input_frames)\n",
        "input_frames = input_frames / 255.0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lql_1ZqYFb-"
      },
      "outputs": [],
      "source": [
        "vgg_predictions = vgg_model.predict(input_frames)\n",
        "resnet_predictions = resnet_model.predict(input_frames)\n",
        "effnet_predictions = effnet_model.predict(input_frames)\n",
        "\n",
        "# Count the number of predictions for each class (0: real, 1: fake)\n",
        "class_counts = np.bincount([np.argmax(vgg_predictions), np.argmax(resnet_predictions), np.argmax(effnet_predictions)])\n",
        "\n",
        "# Get the index of the class with the highest count\n",
        "final_prediction = np.argmax(class_counts)\n",
        "\n",
        "# Print the final prediction\n",
        "if final_prediction == 0:\n",
        "    print(\"The input video is predicted to be real.\")\n",
        "else:\n",
        "    print(\"The input video is predicted to be fake.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocsg9paljgXl"
      },
      "outputs": [],
      "source": [
        "model_e.save(\"effnet_model_6.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_4Xx19Oy39W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}